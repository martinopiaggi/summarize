{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9JJTVDCuTXD"
      },
      "source": [
        "\n",
        "https://github.com/martinopiaggi/summarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "cellView": "form",
        "id": "source_config"
      },
      "outputs": [],
      "source": [
        "# @markdown ## üîó **Source Configuration**\n",
        "\n",
        "# @markdown **Source Type**\n",
        "Type_of_source = \"Google Drive Video Link\"  # @param [\"YouTube Video\", \"Google Drive Video Link\", \"Dropbox Video Link\", \"Local File\"]\n",
        "\n",
        "# @markdown **Source URL or Path**\n",
        "Source = \"https://www.youtube.com/watch?v=SYCOdzb8H0U\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set variables based on user input\n",
        "Type = Type_of_source\n",
        "URL = Source\n",
        "\n",
        "# @markdown **Use YouTube Captions**\n",
        "# @markdown If source is a Youtube video, it's recommended to use the available YouTube captions\n",
        "# @markdown to save on transcription time and API usage.\n",
        "use_Youtube_captions = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ## üé§ **Transcription Settings**\n",
        "# @markdown Settings applied only if using Whisper transcription, not YouTube Captions\n",
        "\n",
        "transcription_method = \"Cloud Whisper\"  # @param [\"Cloud Whisper\", \"Local Whisper\"]\n",
        "language = \"it\"  # @param {type:\"string\"}\n",
        "initial_prompt = \"\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ## üåê **API Configuration**\n",
        "\n",
        "predefined_endpoint = \"Groq\"  # @param [\"OpenAI\", \"Groq\", \"DeepSeek\", \"Perplexity\", \"Google\", \"Hyperbolic\", \"Custom\"]\n",
        "\n",
        "endpoints = {\n",
        "    \"OpenAI\": {\"url\": \"https://api.openai.com/v1\", \"default_model\": \"gpt-4o\", \"key_env\": \"api_key_openai\"},\n",
        "    \"Groq\": {\"url\": \"https://api.groq.com/openai/v1\", \"default_model\": \"llama-3.3-70b-versatile\", \"key_env\": \"api_key_groq\"},\n",
        "    \"DeepSeek\": {\"url\": \"https://api.deepseek.com/v1\", \"default_model\": \"deepseek-chat\", \"key_env\": \"api_key_deepseek\"},\n",
        "    \"Perplexity\": {\"url\": \"https://api.perplexity.ai\", \"default_model\": \"sonar-medium-chat\", \"key_env\": \"api_key_perplexity\"},\n",
        "    \"Google\": {\"url\": \"https://generativelanguage.googleapis.com/v1beta/openai\", \"default_model\": \"gemini-1.5-pro\", \"key_env\": \"api_key_google\"},\n",
        "    \"Hyperbolic\": {\"url\": \"https://api.hyperbolic.xyz/v1\", \"default_model\": \"meta-llama/Llama-3.3-70B-Instruct\", \"key_env\": \"api_key_hyperbolic\"}\n",
        "}\n",
        "\n",
        "use_default_model = True  # @param {type:\"boolean\"}\n",
        "model_name = \"\"  # @param {type:\"string\"}\n",
        "custom_endpoint_url = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# Function to get API key (defined here but called later)\n",
        "def get_api_key():\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        api_key = userdata.get(api_key_env)\n",
        "        if api_key:\n",
        "            print(f\"‚úÖ Found API key in Colab secrets ({api_key_env})\")\n",
        "            return api_key\n",
        "    except: pass\n",
        "\n",
        "    load_dotenv()\n",
        "    api_key = os.getenv(api_key_env) or os.getenv(\"api_key\")\n",
        "    if api_key:\n",
        "        print(f\"‚úÖ Found API key from environment\")\n",
        "        return api_key\n",
        "\n",
        "    print(\"‚ö†Ô∏è No API key found\")\n",
        "    return None\n",
        "\n",
        "# Function to fetch models\n",
        "def fetch_models(base_url, api_key):\n",
        "    import requests\n",
        "    try:\n",
        "        response = requests.get(f\"{base_url}/models\", headers={\"Authorization\": f\"Bearer {api_key}\"}, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            if \"data\" in data: return [model[\"id\"] for model in data[\"data\"]]\n",
        "            if \"models\" in data: return data[\"models\"]\n",
        "        return []\n",
        "    except: return []\n",
        "\n",
        "# Set base URL and model based on selection\n",
        "if predefined_endpoint == \"Custom\":\n",
        "    base_url = custom_endpoint_url\n",
        "    default_model = model_name\n",
        "    api_key_env = \"api_key\"\n",
        "else:\n",
        "    base_url = endpoints[predefined_endpoint][\"url\"]\n",
        "    default_model = endpoints[predefined_endpoint][\"default_model\"]\n",
        "    api_key_env = endpoints[predefined_endpoint][\"key_env\"]\n",
        "\n",
        "model = default_model if use_default_model else model_name"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zuu1NhU6gsJB"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "setup",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ebc2b0-6a17-4f1a-a0a1-d845ee10e901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Found API key in Colab secrets (api_key_groq)\n",
            "‚úÖ Using Groq with model: llama-3.3-70b-versatile\n",
            "\n",
            "Available models:\n",
            "- llama-3.2-11b-vision-preview\n",
            "- llama-3.2-90b-vision-preview\n",
            "- qwen-2.5-32b\n",
            "- gemma2-9b-it\n",
            "- mistral-saba-24b\n",
            "- llama-3.2-3b-preview\n",
            "- llama3-70b-8192\n",
            "- llama-3.3-70b-versatile\n",
            "- qwen-2.5-coder-32b\n",
            "- mixtral-8x7b-32768\n",
            "- llama3-8b-8192\n",
            "- distil-whisper-large-v3-en\n",
            "- llama-3.2-1b-preview\n",
            "- whisper-large-v3-turbo\n",
            "- llama-guard-3-8b\n",
            "- llama-3.1-8b-instant\n",
            "- whisper-large-v3\n",
            "- deepseek-r1-distill-qwen-32b\n",
            "- llama-3.3-70b-specdec\n",
            "- qwen-qwq-32b\n",
            "- deepseek-r1-distill-llama-70b\n"
          ]
        }
      ],
      "source": [
        "# @markdown ## üõ†Ô∏è Install Dependencies and Set Up Environment\n",
        "\n",
        "# Install dependencies silently\n",
        "import os\n",
        "import sys\n",
        "import io\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Capture installation output\n",
        "def install_with_hidden_output(packages):\n",
        "    stdout = sys.stdout\n",
        "    stderr = sys.stderr\n",
        "    str_out = io.StringIO()\n",
        "    str_err = io.StringIO()\n",
        "    sys.stdout = str_out\n",
        "    sys.stderr = str_err\n",
        "    success = True\n",
        "\n",
        "    try:\n",
        "        if isinstance(packages, list):\n",
        "            for package in packages:\n",
        "                !pip install {package} -q\n",
        "        else:\n",
        "            !pip install {packages} -q\n",
        "    except Exception as e:\n",
        "        success = False\n",
        "    finally:\n",
        "        sys.stdout = stdout\n",
        "        sys.stderr = stderr\n",
        "\n",
        "    if not success or \"error\" in str_err.getvalue().lower():\n",
        "        print(\"‚ùå Installation error:\")\n",
        "        print(str_err.getvalue())\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "# Install dependencies silently\n",
        "install_with_hidden_output([\"nest_asyncio\"])\n",
        "install_status = install_with_hidden_output(\"git+https://github.com/martinopiaggi/summarize.git@feature/refactor-backend\")\n",
        "\n",
        "# Only continue if installation was successful\n",
        "if not install_status:\n",
        "    print(\"‚ö†Ô∏è There were issues with installation. Check errors above.\")\n",
        "\n",
        "# Import required modules\n",
        "import nest_asyncio\n",
        "from dotenv import load_dotenv\n",
        "from summarizer import main, CONFIG\n",
        "import asyncio\n",
        "\n",
        "# Apply nest_asyncio for Colab compatibility\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Install source-specific dependencies\n",
        "if Type == \"Google Drive Video Link\":\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "elif Type == \"Local File\":\n",
        "    from google.colab import files\n",
        "\n",
        "# Get transcription key (always need Groq for Cloud Whisper)\n",
        "def get_groq_api_key():\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        groq_api_key = userdata.get('api_key_groq')\n",
        "        if groq_api_key: return groq_api_key\n",
        "    except: pass\n",
        "    return os.getenv('api_key_groq')\n",
        "\n",
        "# Set API keys - NOW WE GET THE API KEY\n",
        "api_key = get_api_key()  # This will print the API key info\n",
        "groq_api_key = get_groq_api_key()\n",
        "\n",
        "# Set environment variables\n",
        "os.environ['api_key'] = api_key or \"\"\n",
        "os.environ['api_key_groq'] = groq_api_key or \"\"\n",
        "\n",
        "# NOW DISPLAY MODEL INFO HERE (moved from Setup to API Configuration)\n",
        "if api_key:\n",
        "    print(f\"‚úÖ Using {predefined_endpoint} with model: {model}\")\n",
        "    available_models = fetch_models(base_url, api_key)\n",
        "\n",
        "    if available_models:\n",
        "        print(f\"\\nAvailable models:\")\n",
        "        for model_item in available_models:\n",
        "            print(f\"- {model_item}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No API key available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "cellView": "form",
        "id": "summary_settings"
      },
      "outputs": [],
      "source": [
        "# @markdown ## ‚öôÔ∏è Configure Summarization Settings\n",
        "prompt_type = \"Summarization\"  # @param ['Summarization', 'Only grammar correction with highlights','Distill Wisdom', 'Questions and answers', 'Essay Writing in Paul Graham Style']\n",
        "parallel_api_calls = 5  # @param {type:\"slider\", min:1, max:60, step:1}\n",
        "chunk_size = 16000      # @param {type:\"slider\", min:2000, max:28000, step:2000}\n",
        "max_output_tokens = 2048  # @param {type:\"slider\", min:1024, max:8192, step:1024}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "run_summary",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "abb3c4a1-6b5d-46f4-ae11-f529bd271b65",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='padding:10px; background:#e8f4ff; border-radius:5px; margin-bottom:15px;'><b>üöÄ Starting summarization...</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='padding:10px; background:#e8fff0; border-radius:5px;'><b>‚úÖ Summary completed!</b> Saved to summary.md</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @markdown ## üöÄ Run Summarization\n",
        "AutoDownload = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# Process local file uploads\n",
        "if Type == \"Local File\" and not URL:\n",
        "    print(\"üìÅ Please upload your video file...\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        URL = list(uploaded.keys())[0]\n",
        "        print(f\"‚úÖ Using uploaded file: {URL}\")\n",
        "\n",
        "# Configure settings\n",
        "CONFIG.update({\n",
        "    \"type_of_source\": Type,\n",
        "    \"source_url_or_path\": URL,\n",
        "    \"use_youtube_captions\": use_Youtube_captions if Type == \"YouTube Video\" else False,\n",
        "    \"transcription_method\": transcription_method,\n",
        "    \"language\": language,\n",
        "    \"initial_prompt\": initial_prompt,\n",
        "    \"prompt_type\": prompt_type,\n",
        "    \"parallel_api_calls\": parallel_api_calls,\n",
        "    \"chunk_size\": chunk_size,\n",
        "    \"max_output_tokens\": max_output_tokens,\n",
        "    \"base_url\": base_url,\n",
        "    \"model\": model,\n",
        "    \"api_key\": api_key  # Pass API key directly\n",
        "})\n",
        "\n",
        "# Progress indicator\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<div style='padding:10px; background:#e8f4ff; border-radius:5px; margin-bottom:15px;'><b>üöÄ Starting summarization...</b></div>\"))\n",
        "\n",
        "try:\n",
        "    # Fixed: Run in main thread with proper event loop handling\n",
        "    from concurrent.futures import ThreadPoolExecutor\n",
        "    import threading\n",
        "\n",
        "    def run_summarizer(config):\n",
        "        # Set a new event loop for this thread\n",
        "        new_loop = asyncio.new_event_loop()\n",
        "        asyncio.set_event_loop(new_loop)\n",
        "        try:\n",
        "            return main(config)\n",
        "        finally:\n",
        "            new_loop.close()\n",
        "\n",
        "    # Run in a separate thread with its own event loop\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        future = executor.submit(run_summarizer, CONFIG)\n",
        "        final_summary = future.result()\n",
        "\n",
        "    # Save to file with metadata\n",
        "    filename = \"summary.md\"\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"# Summary for: {URL}\\n\\n\")\n",
        "        f.write(f\"Generated using: {model} at {base_url}\\n\\n\")\n",
        "        f.write(final_summary)\n",
        "\n",
        "    display(HTML(f\"<div style='padding:10px; background:#e8fff0; border-radius:5px;'><b>‚úÖ Summary completed!</b> Saved to {filename}</div>\"))\n",
        "\n",
        "    # Download button\n",
        "    if AutoDownload:\n",
        "      from google.colab import files\n",
        "      files.download(filename)\n",
        "\n",
        "except Exception as e:\n",
        "    error_message = str(e)\n",
        "    display(HTML(f\"<div style='padding:10px; background:#fff0f0; border-radius:5px;'><b>‚ùå Error:</b> {error_message}</div>\"))\n",
        "\n",
        "    if \"api_key\" in error_message.lower():\n",
        "        display(HTML(\"<div style='padding:10px; background:#fffde7; border-radius:5px; margin-top:10px;'><b>‚ö†Ô∏è</b> Make sure you've set up your API keys correctly!</div>\"))\n",
        "    elif \"ffmpeg\" in error_message.lower():\n",
        "        print(\"\\n‚ö†Ô∏è Installing ffmpeg...\")\n",
        "        !apt-get update && apt-get install -y ffmpeg\n",
        "        print(\"Please run the cell again.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}