{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1n5csfChR4iRIhvaIpuh5hCrgrUiPYXUi?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkogwIy7IfQO"
   },
   "source": [
    "# https://github.com/martinopiaggi/summarize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "jwROe6WH2lZi"
   },
   "outputs": [],
   "source": [
    "# @markdown ## ðŸ”— **Source Configuration**\n",
    "\n",
    "# @markdown **Source Type**\n",
    "Type_of_source = \"YouTube Video\"  # @param [\"YouTube Video\", \"Google Drive Video Link\", \"Dropbox Video Link\", \"Local File\"]\n",
    "\n",
    "# @markdown **Source URL or Path**\n",
    "Source = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set variables based on user input\n",
    "Type = Type_of_source\n",
    "URL = Source\n",
    "\n",
    "# @markdown **Use YouTube Captions**\n",
    "\n",
    "# @markdown If source is a Youtube video, it's recommended to use the available YouTube captions to save on transcription time and API usage. \n",
    "\n",
    "use_Youtube_captions = True  # @param {type:\"boolean\"}\n",
    "\n",
    "# @markdown ---\n",
    "# @markdown ## ðŸŒ **API Configuration**\n",
    "\n",
    "# @markdown The summarization process uses the API key specified in `api_key` variable. \n",
    "# @markdown Ensure you have set the required environment variables or Colab secrets for your API keys.\n",
    "\n",
    "api_endpoint = \"Groq\"  # @param [\"Groq\", \"OpenAI\", \"Custom\"]\n",
    "\n",
    "# Define endpoints and models based on the selected API\n",
    "endpoints = {\n",
    "    \"Groq\": \"https://api.groq.com/openai/v1\",\n",
    "    \"OpenAI\": \"https://api.openai.com/v1\",\n",
    "    \"Custom\": \"http://localhost:1234/v1\"  # Example custom endpoint\n",
    "}\n",
    "base_url = endpoints.get(api_endpoint)\n",
    "\n",
    "# Define models based on the selected API\n",
    "model = {\n",
    "    \"Groq\": \"llama-3.3-70b-versatile\",\n",
    "    \"OpenAI\": \"gpt-4o-mini\",\n",
    "    \"Custom\": \"custom-model-id\"  # Placeholder for any custom model\n",
    "}.get(api_endpoint)\n",
    "\n",
    "# @markdown ---\n",
    "# @markdown ## ðŸŽ¤ **Transcription Settings**\n",
    "# @markdown The transcription settings are applied only if you want to use Whisper transcription and not Youtube Captions. \n",
    "\n",
    "\n",
    "# @markdown If you plan to use Whisper API endpoint (only **Groq** endpoint is supported for now) you have to specify your Groq API key in `api_key_groq`.\n",
    "\n",
    "# @markdown Why use `api_key_groq` and `api_key` ? So that you can use a different API for summarization (e.g., OpenAI), specify the corresponding API key in `api_key`.\n",
    "\n",
    "# @markdown If using locally Whisper: remember to switch the runtime type in Google Colab to a GPU instance (e.g., T4). Go to **Runtime** > **Change runtime type** and select **GPU** as the hardware accelerator.\n",
    "\n",
    "# @markdown **Transcription Method**\n",
    "transcription_method = \"Cloud Whisper\"  # @param [\"Cloud Whisper\", \"Local Whisper\"]\n",
    "\n",
    "# @markdown **Language** (ISO-639-1 code, e.g., \"en\" for English)\n",
    "language = \"auto\"  # @param {type:\"string\"}\n",
    "\n",
    "# @markdown **Initial Prompt for Whisper** (Optional)\n",
    "initial_prompt = \"\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and helper functions\n",
    "Re-run if you change settings in the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "collapsed": true,
    "id": "sJnZWCPc3uOH"
   },
   "outputs": [],
   "source": [
    "# @markdown ## Libraries and helper functions\n",
    "# @markdown Re-run if you change settings in the previous cell\n",
    "\n",
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "!pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if use_Youtube_captions:\n",
    "  !pip install youtube-transcript-api\n",
    "  from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "if (not Type == \"YouTube Video\") or (not use_Youtube_captions):\n",
    "  if transcription_method == \"Local Whisper\":\n",
    "    !pip install openai-whisper\n",
    "    import whisper\n",
    "  else:\n",
    "    !pip install --upgrade groq\n",
    "    from groq import Groq\n",
    "\n",
    "if Type == \"YouTube Video\":\n",
    "  !pip install pytubefix\n",
    "  from pytubefix import YouTube\n",
    "\n",
    "if Type == \"Google Drive Video Link\":\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "# Function to get configuration value\n",
    "def get_api_key():\n",
    "    if api_endpoint == \"Groq\":\n",
    "      return get_groq_api_key()\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        api_key = userdata.get('api_key')\n",
    "    except ImportError:\n",
    "        load_dotenv()\n",
    "        api_key = os.getenv('api_key')\n",
    "\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API key not found in environment variables or Colab secrets\")\n",
    "\n",
    "    return api_key\n",
    "\n",
    "def get_groq_api_key():\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        groq_api_key = userdata.get('api_key_groq')\n",
    "    except ImportError:\n",
    "        load_dotenv()\n",
    "        groq_api_key = os.getenv('api_key_groq')\n",
    "\n",
    "    if not groq_api_key:\n",
    "        raise ValueError(\"Groq API key not found in environment variables or Colab secrets\")\n",
    "\n",
    "    return groq_api_key\n",
    "\n",
    "# Converts the audio file to MP3 with low sample rate and bitrate to reduce the file size (to stay in audio file API limits)\n",
    "def process_audio_file(input_path, output_path):\n",
    "    command_convert = [\n",
    "        'ffmpeg', '-y', '-i', input_path,\n",
    "        '-ar', str(8000),\n",
    "        '-ac', str(1),\n",
    "        '-b:a', '16k',\n",
    "        output_path\n",
    "    ]\n",
    "    subprocess.run(command_convert, check=True)\n",
    "\n",
    "\n",
    "!pip install --upgrade openai\n",
    "import openai\n",
    "client = openai.OpenAI(api_key = get_api_key(), base_url=base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Video fetching\n",
    " Re-run cell if you change the source URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "eLIU6bAX9a9v"
   },
   "outputs": [],
   "source": [
    "# @markdown ## Video fetching\n",
    "# @markdown Re-run cell if you change the source URL\n",
    "skip_transcription=False\n",
    "transcription_text = \"\"\n",
    "textTimestamps = \"\"\n",
    "\n",
    "def seconds_to_time_format(seconds):\n",
    "    hours, remainder = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\"\n",
    "\n",
    "def download_youtube_audio_only(url):\n",
    "    yt = YouTube(url)\n",
    "    audio_stream = yt.streams.get_audio_only()\n",
    "    saved_path = audio_stream.download(output_path=\".\", skip_existing=True)\n",
    "    return saved_path\n",
    "\n",
    "def download_youtube_captions(url):\n",
    "    regex = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
    "    video_id =  re.search(regex, url).group(1)\n",
    "    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "\n",
    "    try:\n",
    "      transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n",
    "    except:\n",
    "      for available_transcript in transcript_list:\n",
    "        if available_transcript.is_translatable:\n",
    "          transcript = available_transcript.translate('en').fetch()\n",
    "          break\n",
    "\n",
    "    transcription_text = \"\"\n",
    "    for entry in transcript:\n",
    "            start_time = seconds_to_time_format(entry['start'])\n",
    "            transcription_text += f\"{start_time} {entry['text'].strip()}\\n\"\n",
    "\n",
    "    transcript_file_name = f\"{video_id}_captions.md\"\n",
    "\n",
    "    with open(transcript_file_name, 'w', encoding='utf-8') as f:\n",
    "      f.write(transcription_text)\n",
    "\n",
    "    return transcription_text,transcript_file_name\n",
    "\n",
    "if Type == \"YouTube Video\":\n",
    "    #clean youtube url from timestamp\n",
    "    URL = re.sub('\\&t=\\d+s?', '', URL)\n",
    "    if use_Youtube_captions:\n",
    "      transcription_text, transcript_file_name = download_youtube_captions(URL)\n",
    "      skip_transcription=True\n",
    "    else:\n",
    "      video_path_local =  download_youtube_audio_only(URL)\n",
    "      # Process the audio file to reduce its size\n",
    "      processed_audio_path = os.path.splitext(video_path_local)[0] + '_processed.mp3'\n",
    "      process_audio_file(video_path_local, processed_audio_path)\n",
    "      video_path_local = processed_audio_path  # Update to the processed file path\n",
    "\n",
    "elif Type == \"Google Drive Video Link\":\n",
    "  subprocess.run(['ffmpeg', '-y', '-i', \"drive/MyDrive/\" + URL, '-vn', '-acodec', 'pcm_s16le',\n",
    "                  '-ar', '16000', '-ac', '1', 'gdrive_audio.wav'], check=True)\n",
    "  video_path_local = \"gdrive_audio.wav\"\n",
    "  # Process the audio file to reduce its size\n",
    "  processed_audio_path = os.path.splitext(video_path_local)[0] + '_processed.mp3'\n",
    "  process_audio_file(video_path_local, processed_audio_path)\n",
    "  video_path_local = processed_audio_path  # Update to the processed file path\n",
    "\n",
    "elif Type == \"Dropbox Video Link\":\n",
    "    subprocess.run(['wget', URL, '-O', 'dropbox_video.mp4'], check=True)\n",
    "    subprocess.run(['ffmpeg', '-y', '-i', 'dropbox_video.mp4', '-vn', '-acodec', 'pcm_s16le',\n",
    "                    '-ar', '16000', '-ac', '1', 'dropbox_video_audio.wav'], check=True)\n",
    "    video_path_local = \"dropbox_video_audio.wav\"\n",
    "    # Process the audio file to reduce its size\n",
    "    processed_audio_path = os.path.splitext(video_path_local)[0] + '_processed.mp3'\n",
    "    process_audio_file(video_path_local, processed_audio_path)\n",
    "    video_path_local = processed_audio_path  # Update to the processed file path\n",
    "\n",
    "elif Type == \"Local File\":\n",
    "    local_file_path = Source\n",
    "    subprocess.run(['ffmpeg', '-y', '-i', local_file_path, '-vn', '-acodec', 'pcm_s16le',\n",
    "                    '-ar', '16000', '-ac', '1', 'local_file_audio.wav'], check=True)\n",
    "    video_path_local = \"local_file_audio.wav\"\n",
    "    # Process the audio file to reduce its size\n",
    "    processed_audio_path = os.path.splitext(video_path_local)[0] + '_processed.mp3'\n",
    "    process_audio_file(video_path_local, processed_audio_path)\n",
    "    video_path_local = processed_audio_path  # Update to the processed file path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcription using Whisper\n",
    "***Only run this cell if the source is not YouTube or you decided not to use YouTube captions.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "iOTFm1vPAVDh"
   },
   "outputs": [],
   "source": [
    "# @markdown ### Transcription\n",
    "# @markdown Re-run cell if you change transcription settings\n",
    "if not skip_transcription:\n",
    "    transcription_text = \"\"\n",
    "\n",
    "    if video_path_local:\n",
    "        # Single file transcription\n",
    "        audio_files = [video_path_local]\n",
    "    else:\n",
    "        # Multiple chunk files\n",
    "        audio_files = audio_chunks\n",
    "\n",
    "    for audio_file_path in audio_files:\n",
    "        if transcription_method == \"Local Whisper\":\n",
    "            # Local Whisper transcription\n",
    "            transcription = model_whisper.transcribe(\n",
    "                audio_file_path,\n",
    "                beam_size=5,\n",
    "                language=None if language == \"auto\" else language,\n",
    "                task=\"translate\",\n",
    "                initial_prompt=initial_prompt or None\n",
    "            )\n",
    "\n",
    "            for segment in transcription[\"segments\"]:\n",
    "                start_time = seconds_to_time_format(segment['start'])\n",
    "                transcription_text += f\"{start_time} {segment['text'].strip()} \"\n",
    "\n",
    "        elif transcription_method == \"Cloud Whisper\":\n",
    "            # Cloud Whisper using Groq API\n",
    "            groq_client = Groq(api_key=get_groq_api_key())\n",
    "            with open(audio_file_path, \"rb\") as audio_file:\n",
    "                transcription_response = groq_client.audio.transcriptions.create(\n",
    "                    file=(os.path.basename(audio_file_path), audio_file.read()),\n",
    "                    model=\"distil-whisper-large-v3-en\" if language == \"en\" else \"whisper-large-v3\",\n",
    "                    prompt=initial_prompt or None,\n",
    "                    response_format=\"verbose_json\",\n",
    "                    language=None if language == \"auto\" else language,\n",
    "                    temperature=0.0\n",
    "                )\n",
    "\n",
    "            # Corrected code using dot notation\n",
    "            for segment in transcription_response.segments:\n",
    "                start_time = seconds_to_time_format(segment['start'])\n",
    "                transcription_text += f\"{start_time} {segment['text'].strip()} \"\n",
    "else:\n",
    "  print(\"Using YouTube captions for transcription.\")\n",
    "\n",
    "# Save the transcription\n",
    "if not skip_transcription:\n",
    "    transcript_file_name = 'transcription.md'\n",
    "    with open(transcript_file_name, 'w', encoding='utf-8') as f:\n",
    "        f.write(transcription_text)\n",
    "else:\n",
    "    transcript_file_name = f\"{video_id}_captions.md\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization and elaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "fWeEGfgFAoni"
   },
   "outputs": [],
   "source": [
    "prompt_type = \"Questions and answers\"  # @param ['Summarization', 'Only grammar correction with highlights','Distill Wisdom', 'Questions and answers']\n",
    "# Fetch prompts using curl\n",
    "prompts = json.loads(subprocess.check_output(['curl', '-s', 'https://raw.githubusercontent.com/martinopiaggi/summarize/refs/heads/main/prompts.json']))\n",
    "summary_prompt = prompts[prompt_type]\n",
    "\n",
    "# @markdown Parallel API calls (mind rate limits)\n",
    "parallel_api_calls = 30 # @param\n",
    "\n",
    "# @markdown Chunk size (tokens) (mind model context length). Higher = less granular summary.\n",
    "# @markdown Rule of thumb: 28k for 3h, 10k for 1h, 5k for 30min, 4k for shorter.\n",
    "chunk_size = 10000 # @param\n",
    "\n",
    "# @markdown Overlap (tokens) between chunks\n",
    "overlap_size = 20 # @param\n",
    "\n",
    "# @markdown Max output tokens of each chunk (mind model limits). Higher = less granular summary.\n",
    "# @markdown Rule of thumb: 4k, 2k or 1k depending on content density.\n",
    "max_output_tokens = 4096 # @param\n",
    "\n",
    "final_summary = \"\"\n",
    "\n",
    "def extract_and_clean_timestamps(text_chunks):\n",
    "    timestamp_pattern = re.compile(r'(\\d{2}:\\d{2}:\\d{2})')\n",
    "    cleaned_texts = []\n",
    "    timestamp_ranges = []\n",
    "    for chunk in text_chunks:\n",
    "        timestamps = timestamp_pattern.findall(chunk)\n",
    "        if timestamps:\n",
    "            for timestamp in timestamps:\n",
    "                # Remove each found timestamp from the chunk\n",
    "                chunk = chunk.replace(timestamp, \"\")\n",
    "            timestamp_ranges.append(timestamps[0])  # Assuming you want the first timestamp per chunk\n",
    "        else:\n",
    "            timestamp_ranges.append(\"\")\n",
    "        cleaned_texts.append(chunk.strip())  # Strip to remove any leading/trailing whitespace\n",
    "    return cleaned_texts, timestamp_ranges\n",
    "\n",
    "def format_timestamp_link(timestamp):\n",
    "    if Type == \"YouTube Video\":\n",
    "      hours, minutes, seconds = map(int, timestamp.split(':'))\n",
    "      total_seconds = hours * 3600 + minutes * 60 + seconds\n",
    "      return f\"{timestamp} - {URL}&t={total_seconds}\"\n",
    "    else:\n",
    "      return f\"{timestamp}\"\n",
    "\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "def summarize(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "            {\"role\": \"system\", \"content\": summary_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=max_output_tokens\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def process_and_summarize(text):\n",
    "    texts = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size - overlap_size)]\n",
    "    cleaned_texts, timestamp_ranges = extract_and_clean_timestamps(texts)\n",
    "    summaries = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=parallel_api_calls) as executor:\n",
    "        future_to_chunk = {executor.submit(summarize, text_chunk): idx for idx, text_chunk in enumerate(cleaned_texts)}\n",
    "        for future in concurrent.futures.as_completed(future_to_chunk):\n",
    "            idx = future_to_chunk[future]\n",
    "            try:\n",
    "                summarized_chunk = future.result()\n",
    "                summary_piece = format_timestamp_link(timestamp_ranges[idx]) + \"\\n\\n\" + summarized_chunk\n",
    "                summary_piece += \"\\n\"\n",
    "                summaries.append((idx, summary_piece))\n",
    "            except Exception as exc:\n",
    "                print(f'Chunk {idx} generated an exception: {exc}')\n",
    "                time.sleep(10)\n",
    "                future_to_chunk[executor.submit(summarize, texts[idx])] = idx\n",
    "\n",
    "    summaries.sort()  # Ensure summaries are in the correct order\n",
    "    final_summary = \"\\n\\n\".join([summary for _, summary in summaries])\n",
    "\n",
    "    # Save the final summary\n",
    "    final_name = transcript_file_name.replace(\".md\", \"_FINAL.md\") if Type != \"Dropbox video link\" else \"final_dropbox_video.md\"\n",
    "    with open(final_name, 'w') as f:\n",
    "        f.write(final_summary)\n",
    "\n",
    "process_and_summarize(transcription_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown Clean folder\n",
    "!rm *.md"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
