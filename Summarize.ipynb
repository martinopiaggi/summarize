{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö **Usage Guide & Tips**\n",
    "\n",
    "### ‚úÖ **Quick Start**\n",
    "1. **Set your source** in the first cell (YouTube, Google Drive, Dropbox, or Local)\n",
    "2. **Choose your API provider** and model in the second cell\n",
    "3. **Run the setup cell** - it will guide you through API key configuration\n",
    "4. **Adjust settings** like prompt type and chunk size in the fourth cell\n",
    "5. **Hit Run** in the final cell and watch the magic happen!\n",
    "\n",
    "### üîë **API Key Setup**\n",
    "- **Colab Secrets** (Recommended): Go to üîí Secrets in the sidebar, add your API key with the name shown in setup\n",
    "- **Environment File**: Create a `.env` file with your keys like `perplexity=pplx-your-key-here`\n",
    "\n",
    "### üí° **Tips for Best Results**\n",
    "- **YouTube videos**: Leave captions enabled for speed and cost efficiency\n",
    "- **Long videos**: Use smaller chunk sizes (8000-12000) for better context\n",
    "- **Multiple languages**: Set the language parameter correctly\n",
    "- **Complex content**: Try \"Research\" or \"Distill Wisdom\" prompt types\n",
    "- **Performance**: Increase parallel calls (20-30) for faster processing\n",
    "\n",
    "### üéØ **Prompt Types Explained**\n",
    "- **Summarization**: General overview and key points\n",
    "- **Questions and answers**: Structured Q&A format\n",
    "- **Distill Wisdom**: Key insights, quotes, and takeaways\n",
    "- **Research**: Academic-style analysis and findings\n",
    "- **Fact Checker**: Verification and accuracy analysis\n",
    "\n",
    "### üöÄ **Advanced Features**\n",
    "- **Verbose Output**: Enable to see detailed progress with spinners and progress bars\n",
    "- **Custom Models**: Switch to specific models for different tasks\n",
    "- **Batch Processing**: Process multiple videos by running cells repeatedly\n",
    "- **Auto Download**: Enable to automatically download results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9JJTVDCuTXD"
   },
   "source": [
    "\n",
    "https://github.com/martinopiaggi/summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "source_config"
   },
   "outputs": [],
   "source": [
    "# @markdown ## üîó **Source Configuration**\n",
    "\n",
    "# @markdown **Source Type**\n",
    "Type_of_source = \"YouTube Video\"  # @param [\"YouTube Video\", \"Google Drive Video Link\", \"Dropbox Video Link\", \"Local File\"]\n",
    "\n",
    "# @markdown **Source URL or Path**\n",
    "Source = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# @markdown **Use YouTube Captions** (Recommended for speed and cost efficiency)\n",
    "use_Youtube_captions = True  # @param {type:\"boolean\"}\n",
    "\n",
    "# @markdown ## üé§ **Transcription Settings** (Only used if captions unavailable)\n",
    "transcription_method = \"Cloud Whisper\"  # @param [\"Cloud Whisper\", \"Local Whisper\"]\n",
    "language = \"it\"  # @param [\"en\", \"es\", \"fr\", \"de\", \"it\", \"pt\", \"auto\"]\n",
    "\n",
    "print(f\"üìÅ Source Type: {Type_of_source}\")\n",
    "print(f\"üîó Source: {Source}\")\n",
    "print(f\"üìã Using captions: {'‚úÖ Yes' if use_Youtube_captions else '‚ùå No (will transcribe)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "zuu1NhU6gsJB"
   },
   "outputs": [],
   "source": [
    "# @markdown ## üåê **API Configuration**\n",
    "\n",
    "predefined_endpoint = \"Perplexity\"  # @param [\"OpenAI\", \"Groq\", \"DeepSeek\", \"Perplexity\", \"Google\", \"Hyperbolic\", \"Custom\"]\n",
    "\n",
    "# Modern endpoint configurations with correct environment variable mapping\n",
    "endpoints = {\n",
    "    \"OpenAI\": {\"url\": \"https://api.openai.com/v1\", \"default_model\": \"gpt-4o\", \"key_env\": \"openai\"},\n",
    "    \"Groq\": {\"url\": \"https://api.groq.com/openai/v1\", \"default_model\": \"llama-3.3-70b-versatile\", \"key_env\": \"groq\"},\n",
    "    \"DeepSeek\": {\"url\": \"https://api.deepseek.com/v1\", \"default_model\": \"deepseek-chat\", \"key_env\": \"deepseek\"},\n",
    "    \"Perplexity\": {\"url\": \"https://api.perplexity.ai\", \"default_model\": \"sonar-pro\", \"key_env\": \"perplexity\"},\n",
    "    \"Google\": {\"url\": \"https://generativelanguage.googleapis.com/v1beta/openai\", \"default_model\": \"gemini-2.0-flash-exp\", \"key_env\": \"generativelanguage\"},\n",
    "    \"Hyperbolic\": {\"url\": \"https://api.hyperbolic.xyz/v1\", \"default_model\": \"meta-llama/Llama-3.3-70B-Instruct\", \"key_env\": \"hyperbolic\"}\n",
    "}\n",
    "\n",
    "use_default_model = True  # @param {type:\"boolean\"}\n",
    "custom_model = \"gpt-4o\"  # @param {type:\"string\"}\n",
    "custom_endpoint_url = \"https://api.openai.com/v1\"  # @param {type:\"string\"}\n",
    "\n",
    "# Configure endpoint and model\n",
    "if predefined_endpoint == \"Custom\":\n",
    "    base_url = custom_endpoint_url\n",
    "    model = custom_model\n",
    "    key_env = \"openai\"  # Default fallback\n",
    "else:\n",
    "    config = endpoints[predefined_endpoint]\n",
    "    base_url = config[\"url\"]\n",
    "    model = config[\"default_model\"] if use_default_model else custom_model\n",
    "    key_env = config[\"key_env\"]\n",
    "\n",
    "print(f\"üåê Using: {predefined_endpoint}\")\n",
    "print(f\"üîó Endpoint: {base_url}\")\n",
    "print(f\"ü§ñ Model: {model}\")\n",
    "print(f\"üîë Expected env key: {key_env}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "setup",
    "outputId": "2dea0106-9aa8-4b1e-e202-b0d172cd25d5"
   },
   "outputs": [],
   "source": "# @markdown ## üõ†Ô∏è **Setup Dependencies**\n\nimport os\nimport sys\nfrom IPython.display import display, HTML, clear_output\n\ndef show_status(message, status=\"info\"):\n    \"\"\"Display status with nice formatting\"\"\"\n    colors = {\n        \"info\": \"#e3f2fd\", \"success\": \"#e8f5e8\", \n        \"warning\": \"#fff3e0\", \"error\": \"#ffebee\"\n    }\n    symbols = {\n        \"info\": \"‚ÑπÔ∏è\", \"success\": \"‚úÖ\", \n        \"warning\": \"‚ö†Ô∏è\", \"error\": \"‚ùå\"\n    }\n    color = colors.get(status, colors[\"info\"])\n    symbol = symbols.get(status, symbols[\"info\"])\n    \n    display(HTML(f\"\"\"\n    <div style='padding: 12px; background: {color}; border-radius: 8px; \n                 margin: 8px 0; border-left: 4px solid #2196F3;'>\n        <b>{symbol} {message}</b>\n    </div>\n    \"\"\"))\n\nshow_status(\"Setting up environment...\", \"info\")\n\n# Install required packages\ntry:\n    # Essential packages for all functionality\n    !pip install nest_asyncio python-dotenv groq -q\n    \n    # Install the summarizer package from the latest commit\n    !pip install --upgrade \"git+https://github.com/martinopiaggi/summarize.git@feature/refactor-backend\" -q\n    \n    show_status(\"Core dependencies installed successfully\", \"success\")\n    \n    # Optional: Install Local Whisper (only if user wants local transcription)\n    if transcription_method == \"Local Whisper\":\n        show_status(\"Installing OpenAI Whisper for local transcription...\", \"info\")\n        !pip install openai-whisper -q\n        show_status(\"Local Whisper installed\", \"success\")\n    else:\n        show_status(\"Using Cloud Whisper (via Groq API) - no local Whisper needed\", \"info\")\n    \nexcept Exception as e:\n    show_status(f\"Installation error: {str(e)}\", \"error\")\n    show_status(\"Trying alternative installation...\", \"warning\")\n    !pip install nest_asyncio python-dotenv groq\n    !pip install --upgrade \"git+https://github.com/martinopiaggi/summarize.git@feature/refactor-backend\"\n\n# Import and configure\ntry:\n    import nest_asyncio\n    import asyncio\n    from dotenv import load_dotenv\n    from summarizer.core import main\n    \n    # Fix async event loop for Jupyter\n    nest_asyncio.apply()\n    \n    # Ensure we have a clean event loop\n    try:\n        loop = asyncio.get_running_loop()\n        show_status(\"Using existing Jupyter event loop\", \"info\")\n    except RuntimeError:\n        # No running loop, create one\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        show_status(\"Created new event loop\", \"info\")\n    \n    load_dotenv()\n    \n    show_status(\"Summarizer loaded successfully\", \"success\")\n    \nexcept ImportError as e:\n    show_status(f\"Import error: {str(e)}\", \"error\")\n    show_status(\"Please restart runtime and try again\", \"warning\")\n\n# API Key Management\ndef get_api_key():\n    \"\"\"Get API key from Colab secrets or environment\"\"\"\n    api_key = None\n    \n    # Try Colab secrets first\n    try:\n        from google.colab import userdata\n        api_key = userdata.get(key_env)\n        if api_key:\n            show_status(f\"Found API key in Colab secrets ({key_env})\", \"success\")\n            return api_key\n    except:\n        pass\n    \n    # Try environment variables\n    api_key = os.getenv(key_env)\n    if api_key:\n        show_status(f\"Found API key in environment ({key_env})\", \"success\")\n        return api_key\n        \n    show_status(f\"No API key found for '{key_env}'. Please add it to Colab secrets or .env file\", \"warning\")\n    return None\n\n# Get API keys\nmain_api_key = get_api_key()\n\n# For transcription - check what's needed based on method\nif transcription_method == \"Cloud Whisper\":\n    groq_key = None\n    try:\n        from google.colab import userdata\n        groq_key = userdata.get('groq')\n    except:\n        pass\n    if not groq_key:\n        groq_key = os.getenv('groq')\n    \n    if groq_key:\n        show_status(\"Groq API key found for Cloud Whisper\", \"success\")\n    else:\n        show_status(\"Groq API key needed for Cloud Whisper transcription\", \"warning\")\n        show_status(\"Add 'groq' to Colab secrets or .env file\", \"info\")\n    \n    os.environ['groq'] = groq_key or \"\"\n\nelif transcription_method == \"Local Whisper\":\n    # Check if openai-whisper is available\n    try:\n        import whisper\n        show_status(\"Local Whisper (OpenAI) package available\", \"success\")\n    except ImportError:\n        show_status(\"Local Whisper package not installed\", \"warning\")\n        show_status(\"Run: !pip install openai-whisper\", \"info\")\n\n# Set environment variables for the summarizer\nos.environ[key_env] = main_api_key or \"\"\n\nprint(f\"üîß Setup complete for {predefined_endpoint} with {transcription_method}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "summary_settings"
   },
   "outputs": [],
   "source": [
    "# @markdown ## ‚öôÔ∏è **Summarization Settings**\n",
    "\n",
    "prompt_type = \"Questions and answers\"  # @param ['Summarization', 'Only grammar correction with highlights', 'Distill Wisdom', 'Questions and answers', 'DNA Extractor', 'Research', 'Fact Checker', 'Essay Writing in Paul Graham Style']\n",
    "chunk_size = 12000  # @param {type:\"slider\", min:4000, max:28000, step:2000}\n",
    "parallel_api_calls = 20  # @param {type:\"slider\", min:1, max:50, step:1}\n",
    "max_output_tokens = 4096  # @param {type:\"slider\", min:1024, max:8192, step:1024}\n",
    "\n",
    "# @markdown **Visual Feedback**\n",
    "verbose_output = True  # @param {type:\"boolean\"}\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration Summary:\")\n",
    "print(f\"üìù Prompt Type: {prompt_type}\")\n",
    "print(f\"üìä Chunk Size: {chunk_size:,} characters\")\n",
    "print(f\"üîÄ Parallel Calls: {parallel_api_calls}\")\n",
    "print(f\"üéØ Max Tokens: {max_output_tokens:,}\")\n",
    "print(f\"üëÅÔ∏è Verbose Output: {'‚úÖ Enabled' if verbose_output else '‚ùå Disabled'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "run_summary",
    "outputId": "abb3c4a1-6b5d-46f4-ae11-f529bd271b65"
   },
   "outputs": [],
   "source": [
    "# @markdown ## üöÄ **Run Summarization**\n",
    "\n",
    "auto_download = False  # @param {type:\"boolean\"}\n",
    "\n",
    "import time\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Handle local file uploads if needed\n",
    "if Type_of_source == \"Local File\" and not Source:\n",
    "    show_status(\"Please upload your video file...\", \"info\")\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    if uploaded:\n",
    "        Source = list(uploaded.keys())[0]\n",
    "        show_status(f\"Using uploaded file: {Source}\", \"success\")\n",
    "    else:\n",
    "        show_status(\"No file uploaded. Please try again.\", \"error\")\n",
    "        raise ValueError(\"No file provided\")\n",
    "\n",
    "# Mount Google Drive if needed\n",
    "if Type_of_source == \"Google Drive Video Link\":\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        show_status(\"Google Drive mounted successfully\", \"success\")\n",
    "    except Exception as e:\n",
    "        show_status(f\"Failed to mount Google Drive: {str(e)}\", \"error\")\n",
    "\n",
    "# Configure the summarizer\n",
    "config = {\n",
    "    \"type_of_source\": Type_of_source,\n",
    "    \"source_url_or_path\": Source,\n",
    "    \"use_youtube_captions\": use_Youtube_captions if Type_of_source == \"YouTube Video\" else False,\n",
    "    \"transcription_method\": transcription_method,\n",
    "    \"language\": language,\n",
    "    \"prompt_type\": prompt_type,\n",
    "    \"chunk_size\": chunk_size,\n",
    "    \"parallel_api_calls\": parallel_api_calls,\n",
    "    \"max_output_tokens\": max_output_tokens,\n",
    "    \"base_url\": base_url,\n",
    "    \"model\": model,\n",
    "    \"verbose\": verbose_output  # Enable new visual feedback system\n",
    "}\n",
    "\n",
    "# Validate API key before starting\n",
    "if not main_api_key:\n",
    "    show_status(f\"Missing API key for {predefined_endpoint}. Please configure it in the setup cell.\", \"error\")\n",
    "    raise ValueError(\"API key required\")\n",
    "\n",
    "def run_summarizer_in_thread(config):\n",
    "    \"\"\"Run summarizer in a separate thread with its own event loop to avoid conflicts\"\"\"\n",
    "    # Create a new event loop for this thread\n",
    "    new_loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(new_loop)\n",
    "    \n",
    "    try:\n",
    "        return main(config)\n",
    "    finally:\n",
    "        new_loop.close()\n",
    "\n",
    "# Show processing start\n",
    "show_status(f\"Starting summarization with {model}...\", \"info\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Run the summarizer in a separate thread to avoid event loop conflicts\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        future = executor.submit(run_summarizer_in_thread, config)\n",
    "        summary = future.result()  # This will block until completion\n",
    "    \n",
    "    # Calculate processing time\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    mins, secs = divmod(duration, 60)\n",
    "    \n",
    "    show_status(f\"Summarization completed in {int(mins)}m {int(secs)}s\", \"success\")\n",
    "    \n",
    "    # Generate filename with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    safe_source = Source.split('/')[-1].replace('?', '_').replace('&', '_')[:50]\n",
    "    filename = f\"summary_{safe_source}_{timestamp}.md\"\n",
    "    \n",
    "    # Save the summary\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# Video Summary\\n\\n\")\n",
    "        f.write(f\"**Source:** {Source}\\n\")\n",
    "        f.write(f\"**Model:** {model} ({predefined_endpoint})\\n\")\n",
    "        f.write(f\"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"**Processing Time:** {int(mins)}m {int(secs)}s\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        f.write(summary)\n",
    "    \n",
    "    show_status(f\"Summary saved as: {filename}\", \"success\")\n",
    "    \n",
    "    # Display preview\n",
    "    preview_length = 500\n",
    "    preview = summary[:preview_length] + (\"...\" if len(summary) > preview_length else \"\")\n",
    "    \n",
    "    display(HTML(f\"\"\"\n",
    "    <div style='padding: 15px; background: #f8f9fa; border-radius: 8px; \n",
    "                 margin: 15px 0; border: 1px solid #dee2e6;'>\n",
    "        <h3>üìÑ Summary Preview</h3>\n",
    "        <div style='background: white; padding: 15px; border-radius: 5px; \n",
    "                    font-family: system-ui; line-height: 1.6; max-height: 300px; \n",
    "                    overflow-y: auto;'>\n",
    "            {preview.replace(chr(10), '<br>')}\n",
    "        </div>\n",
    "        <small style='color: #6c757d;'>\n",
    "            Full summary saved to: <code>{filename}</code> \n",
    "            ({len(summary):,} characters)\n",
    "        </small>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Auto-download if requested\n",
    "    if auto_download:\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            files.download(filename)\n",
    "            show_status(\"File downloaded successfully\", \"success\")\n",
    "        except Exception as e:\n",
    "            show_status(f\"Download failed: {str(e)}\", \"warning\")\n",
    "            \n",
    "except Exception as e:\n",
    "    error_msg = str(e)\n",
    "    show_status(f\"Summarization failed: {error_msg}\", \"error\")\n",
    "    \n",
    "    # Provide helpful error suggestions\n",
    "    if \"api\" in error_msg.lower() or \"key\" in error_msg.lower():\n",
    "        show_status(\"Check your API key configuration\", \"warning\")\n",
    "    elif \"transcript\" in error_msg.lower():\n",
    "        show_status(\"Try enabling 'Use YouTube Captions' or check the video URL\", \"warning\")\n",
    "    elif \"ffmpeg\" in error_msg.lower():\n",
    "        show_status(\"Installing ffmpeg...\", \"info\")\n",
    "        !apt-get update -q && apt-get install -y ffmpeg -q\n",
    "        show_status(\"Please run this cell again\", \"info\")\n",
    "    else:\n",
    "        show_status(\"Check your configuration and try again\", \"warning\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}